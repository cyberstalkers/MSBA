{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLAIF: Predicting Stock Return\n",
    "\n",
    "\n",
    "Submit report includes:\n",
    "1. Present the detailed steps of the exercise (1 points)\n",
    "2. Find your final best model (highest accuracy you can get) (2 points)\n",
    "3. Evaluate the performance of the model (1 points)\n",
    "4. Code (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Data Loading and Preprosessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        open       high        low      close    volume       amount\n",
      "0  3394.5740  3394.5740  3394.5740  3394.5740  177127.0  247062735.6\n",
      "1  3388.2855  3388.2855  3381.3847  3381.3847  342509.0  506723446.2\n",
      "2  3379.9758  3379.9758  3377.1050  3377.1050  235704.0  347825009.2\n",
      "3  3376.9107  3376.9107  3375.5988  3376.6061  298665.0  421905301.0\n",
      "4  3375.8573  3375.8573  3375.1275  3375.5162  299740.0  426854063.8\n"
     ]
    }
   ],
   "source": [
    "# Set seeds\n",
    "np.random.seed(1)\n",
    "\n",
    "# Load the dataset\n",
    "os.chdir('~')\n",
    "\n",
    "dataset = pd.read_excel('sample_dataset.xlsx')\n",
    "dataset = dataset.dropna()\n",
    "dataset = dataset[['open', 'high', 'low', 'close','volume', 'amount']]\n",
    "\n",
    "\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Models Construction (features engineering, deep learning and model evaluation)\n",
    "In this case, use deep neural network and long short term memory model to predict the trend of stock prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: NN\n",
    "The model is based on:\n",
    "$$ y_{t+1} = f(open, high, low, volumn, amount) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in greater\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in greater\n",
      "  from ipykernel import kernelapp as app\n",
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in greater\n",
      "  app.launch_new_instance()\n",
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in greater\n",
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in greater\n",
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in greater\n"
     ]
    }
   ],
   "source": [
    "# Split into input (X1) and output (Y1) variables\n",
    "rawdata = pd.read_excel('MFIN7034_A3_dataset.xlsx')\n",
    "X1 = rawdata\n",
    "X1 = X1.drop('DATETIME',axis=1)\n",
    "X1 = X1.drop('close',axis=1)\n",
    "Y1 = rawdata['close']\n",
    "\n",
    "# Data processing Y1 to 1 if tick return positive else 0\n",
    "Y1 = (Y1.shift(1)-Y1)/Y1\n",
    "Y1=Y1.shift(-1)\n",
    "Y1.drop(Y1.shape[0] -1,inplace =True)\n",
    "Y1=pd.Series(np.where(Y1.values > 0 , 1,0),Y1.index)\n",
    "\n",
    "# Data processing X1 to 1 if tick increase positive else 0\n",
    "X1=X1.pct_change()\n",
    "X1=X1.shift(-1)\n",
    "X1=X1.drop(X1.index[397982])\n",
    "X1['open']=pd.Series(np.where(X1.open.values > 0 , 1,0),X1.index)\n",
    "X1['high']=pd.Series(np.where(X1.high.values > 0 , 1,0),X1.index)\n",
    "X1['low']=pd.Series(np.where(X1.low.values > 0 , 1,0),X1.index)\n",
    "X1['volume']=pd.Series(np.where(X1.volume.values > 0 , 1,0),X1.index)\n",
    "X1['amount']=pd.Series(np.where(X1.amount.values > 0 , 1,0),X1.index)\n",
    "\n",
    "\n",
    "# Training set (60%)\n",
    "X = X1.loc[0:238789,]\n",
    "Y = Y1.loc[0:238789,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model 1 parallel NN 20 neurons, epochs=20, batch_size=40\n",
    "n=20\n",
    "model = Sequential()\n",
    "model.add(Dense(n, input_dim=5, activation='relu'))\n",
    "model.add(Dense(n, activation='relu'))\n",
    "model.add(Dense(n, activation='relu'))\n",
    "model.add(Dense(n, activation='relu'))\n",
    "model.add(Dense(n, activation='relu'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=40 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model 1\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tuning parameters and set BatchNormalization\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=5))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2, activation='relu'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, Y, epochs=20, batch_size=40 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model again by using CV and testing sets.\n",
    "\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "Xcv = X1.loc[238791:318887,]\n",
    "Ycv = Y1.loc[238791:318887,]\n",
    "#Ycv = to_categorical(Ycv, num_classes=2)\n",
    "score = model.evaluate(Xcv,Ycv)\n",
    "print('Accuracy of cross validation set',score[1])\n",
    "\n",
    "Xtest = X1.loc[318888:398982,]\n",
    "Ytest = Y1.loc[318888:398982,]\n",
    "#Ytest = to_categorical(Ytest, num_classes=2)\n",
    "score = model.evaluate(Xtest,Ytest)\n",
    "print('Accuracy of testing set',score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: LSTM\n",
    "The model is based on:\n",
    "$$ y_{t+1} = f(x_t, x_t^2, volumn, amount) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>amount</th>\n",
       "      <th>close2</th>\n",
       "      <th>Price_Rise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3388.2855</td>\n",
       "      <td>3388.2855</td>\n",
       "      <td>3381.3847</td>\n",
       "      <td>3381.3847</td>\n",
       "      <td>342509.0</td>\n",
       "      <td>506723446.2</td>\n",
       "      <td>1.152313e+07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3379.9758</td>\n",
       "      <td>3379.9758</td>\n",
       "      <td>3377.1050</td>\n",
       "      <td>3377.1050</td>\n",
       "      <td>235704.0</td>\n",
       "      <td>347825009.2</td>\n",
       "      <td>1.143376e+07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3376.9107</td>\n",
       "      <td>3376.9107</td>\n",
       "      <td>3375.5988</td>\n",
       "      <td>3376.6061</td>\n",
       "      <td>298665.0</td>\n",
       "      <td>421905301.0</td>\n",
       "      <td>1.140484e+07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3375.8573</td>\n",
       "      <td>3375.8573</td>\n",
       "      <td>3375.1275</td>\n",
       "      <td>3375.5162</td>\n",
       "      <td>299740.0</td>\n",
       "      <td>426854063.8</td>\n",
       "      <td>1.140147e+07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3375.6936</td>\n",
       "      <td>3375.6936</td>\n",
       "      <td>3374.9391</td>\n",
       "      <td>3375.5097</td>\n",
       "      <td>273694.0</td>\n",
       "      <td>394890093.5</td>\n",
       "      <td>1.139411e+07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        open       high        low      close    volume       amount  \\\n",
       "1  3388.2855  3388.2855  3381.3847  3381.3847  342509.0  506723446.2   \n",
       "2  3379.9758  3379.9758  3377.1050  3377.1050  235704.0  347825009.2   \n",
       "3  3376.9107  3376.9107  3375.5988  3376.6061  298665.0  421905301.0   \n",
       "4  3375.8573  3375.8573  3375.1275  3375.5162  299740.0  426854063.8   \n",
       "5  3375.6936  3375.6936  3374.9391  3375.5097  273694.0  394890093.5   \n",
       "\n",
       "         close2  Price_Rise  \n",
       "1  1.152313e+07           0  \n",
       "2  1.143376e+07           0  \n",
       "3  1.140484e+07           0  \n",
       "4  1.140147e+07           0  \n",
       "5  1.139411e+07           1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new features\n",
    "dataset['close2']= dataset['close'].shift(1)**2\n",
    "\n",
    "# Define dummy variable: trend of stock price\n",
    "dataset['Price_Rise'] = np.where(dataset['close'].shift(-1) > dataset['close'], 1, 0)\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is: \n",
      " (318365, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "# Extract X and y\n",
    "X = dataset.iloc[:, 3:-1]\n",
    "y = dataset.iloc[:, -1]\n",
    "\n",
    "# Create training and testing sets\n",
    "split = int(len(dataset)*0.8)\n",
    "X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n",
    "\n",
    "# Normalize the feature values\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# reshaping - Adding time interval as a dimension for input.\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1])) # time_steps = 1\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "print('The shape of X_train is: \\n', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "318365/318365 [==============================] - 10s - loss: 0.6928 - acc: 0.5109    \n",
      "Epoch 2/30\n",
      "318365/318365 [==============================] - 10s - loss: 0.6925 - acc: 0.5135    \n",
      "Epoch 3/30\n",
      "318365/318365 [==============================] - 9s - loss: 0.6925 - acc: 0.5149     \n",
      "Epoch 4/30\n",
      "318365/318365 [==============================] - 10s - loss: 0.6924 - acc: 0.5157    \n",
      "Epoch 5/30\n",
      "318365/318365 [==============================] - 10s - loss: 0.6924 - acc: 0.5155    \n",
      "Epoch 6/30\n",
      "318365/318365 [==============================] - 10s - loss: 0.6923 - acc: 0.5166    \n",
      "Epoch 7/30\n",
      "318365/318365 [==============================] - 10s - loss: 0.6923 - acc: 0.5161    \n",
      "Epoch 8/30\n",
      "318365/318365 [==============================] - 10s - loss: 0.6923 - acc: 0.5166    \n",
      "Epoch 9/30\n",
      "318365/318365 [==============================] - 10s - loss: 0.6922 - acc: 0.5163    \n",
      "Epoch 10/30\n",
      "318365/318365 [==============================] - 10s - loss: 0.6922 - acc: 0.5168    \n",
      "Epoch 11/30\n",
      "318365/318365 [==============================] - 10s - loss: 0.6922 - acc: 0.5166    \n",
      "Epoch 12/30\n",
      "318365/318365 [==============================] - 10s - loss: 0.6922 - acc: 0.5171    \n",
      "Epoch 13/30\n",
      "318365/318365 [==============================] - 10s - loss: 0.6922 - acc: 0.5159    \n",
      "Epoch 14/30\n",
      "318365/318365 [==============================] - 12s - loss: 0.6922 - acc: 0.5164    \n",
      "Epoch 15/30\n",
      "318365/318365 [==============================] - 11s - loss: 0.6921 - acc: 0.5169    \n",
      "Epoch 16/30\n",
      "318365/318365 [==============================] - 11s - loss: 0.6921 - acc: 0.5177    \n",
      "Epoch 17/30\n",
      "318365/318365 [==============================] - 11s - loss: 0.6921 - acc: 0.5170    \n",
      "Epoch 18/30\n",
      "318365/318365 [==============================] - 13s - loss: 0.6921 - acc: 0.5179    \n",
      "Epoch 19/30\n",
      "318365/318365 [==============================] - 10s - loss: 0.6920 - acc: 0.5177    \n",
      "Epoch 20/30\n",
      "318365/318365 [==============================] - 11s - loss: 0.6921 - acc: 0.5183    \n",
      "Epoch 21/30\n",
      "318365/318365 [==============================] - 12s - loss: 0.6920 - acc: 0.5172    \n",
      "Epoch 22/30\n",
      "318365/318365 [==============================] - 11s - loss: 0.6920 - acc: 0.5179    \n",
      "Epoch 23/30\n",
      "318365/318365 [==============================] - 10s - loss: 0.6920 - acc: 0.5184    \n",
      "Epoch 24/30\n",
      "318365/318365 [==============================] - 10s - loss: 0.6919 - acc: 0.5195    \n",
      "Epoch 25/30\n",
      "318365/318365 [==============================] - 10s - loss: 0.6919 - acc: 0.5194    \n",
      "Epoch 26/30\n",
      "318365/318365 [==============================] - 10s - loss: 0.6918 - acc: 0.5197    \n",
      "Epoch 27/30\n",
      "318365/318365 [==============================] - 10s - loss: 0.6918 - acc: 0.5198    \n",
      "Epoch 28/30\n",
      "318365/318365 [==============================] - 11s - loss: 0.6918 - acc: 0.5199    \n",
      "Epoch 29/30\n",
      "318365/318365 [==============================] - 11s - loss: 0.6917 - acc: 0.5203    \n",
      "Epoch 30/30\n",
      "318365/318365 [==============================] - 11s - loss: 0.6916 - acc: 0.5203    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a236714e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the RNN(LSTM)\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "# Initialising the RNN\n",
    "# Creating an object of Sequential class to create the RNN.\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the LSTM layer\n",
    "# input_shape = (len_of_seq, nb_of_features)\n",
    "classifier.add(LSTM(units = 32, activation = 'relu', input_shape = (X_train.shape[1],X_train.shape[2]), return_sequences=False))\n",
    "\n",
    "# Adding the output layer\n",
    "# 1 nueron in the output layer for 1 dimensional output\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the RNN\n",
    "# Compiling all the layers together.\n",
    "# Loss helps in manipulation of weights in NN. \n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "# Number of epochs increased for better convergence.\n",
    "classifier.fit(X_train, y_train, batch_size = 200, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78688/79592 [============================>.] - ETA: 0s\n",
      "acc: 50.78%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "scores = classifier.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"\\n%s: %.2f%%\" % (classifier.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: LSTM\n",
    "The model is based on:\n",
    "$$ y_{t+1} = f(HL, OC, 3m MA, 10m MA, 30m MA, volatility) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>amount</th>\n",
       "      <th>H-L</th>\n",
       "      <th>O-C</th>\n",
       "      <th>3m MA</th>\n",
       "      <th>10m MA</th>\n",
       "      <th>30m MA</th>\n",
       "      <th>Std_dev</th>\n",
       "      <th>Price_Rise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3358.1065</td>\n",
       "      <td>3358.1065</td>\n",
       "      <td>3358.1065</td>\n",
       "      <td>3360.5149</td>\n",
       "      <td>244622.0</td>\n",
       "      <td>369415381.4</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.4084</td>\n",
       "      <td>3356.039733</td>\n",
       "      <td>3356.71862</td>\n",
       "      <td>3367.570947</td>\n",
       "      <td>2.508297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3360.4355</td>\n",
       "      <td>3360.4355</td>\n",
       "      <td>3360.4340</td>\n",
       "      <td>3362.4217</td>\n",
       "      <td>256421.0</td>\n",
       "      <td>364852618.5</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>1.9862</td>\n",
       "      <td>3358.064533</td>\n",
       "      <td>3356.62247</td>\n",
       "      <td>3366.435643</td>\n",
       "      <td>3.299309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3362.3333</td>\n",
       "      <td>3362.3333</td>\n",
       "      <td>3362.3333</td>\n",
       "      <td>3364.5874</td>\n",
       "      <td>227649.0</td>\n",
       "      <td>348879482.7</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.2541</td>\n",
       "      <td>3360.299800</td>\n",
       "      <td>3356.95353</td>\n",
       "      <td>3365.803543</td>\n",
       "      <td>3.513844</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3364.9953</td>\n",
       "      <td>3364.9953</td>\n",
       "      <td>3364.9780</td>\n",
       "      <td>3365.5744</td>\n",
       "      <td>219018.0</td>\n",
       "      <td>327010766.0</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.5791</td>\n",
       "      <td>3362.508000</td>\n",
       "      <td>3357.73911</td>\n",
       "      <td>3365.386290</td>\n",
       "      <td>3.079289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3365.9502</td>\n",
       "      <td>3365.9502</td>\n",
       "      <td>3365.9502</td>\n",
       "      <td>3366.4954</td>\n",
       "      <td>225914.0</td>\n",
       "      <td>341952828.2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5452</td>\n",
       "      <td>3364.194500</td>\n",
       "      <td>3358.75224</td>\n",
       "      <td>3365.018567</td>\n",
       "      <td>2.431807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         open       high        low      close    volume       amount     H-L  \\\n",
       "30  3358.1065  3358.1065  3358.1065  3360.5149  244622.0  369415381.4  0.0000   \n",
       "31  3360.4355  3360.4355  3360.4340  3362.4217  256421.0  364852618.5  0.0015   \n",
       "32  3362.3333  3362.3333  3362.3333  3364.5874  227649.0  348879482.7  0.0000   \n",
       "33  3364.9953  3364.9953  3364.9780  3365.5744  219018.0  327010766.0  0.0173   \n",
       "34  3365.9502  3365.9502  3365.9502  3366.4954  225914.0  341952828.2  0.0000   \n",
       "\n",
       "       O-C        3m MA      10m MA       30m MA   Std_dev  Price_Rise  \n",
       "30  2.4084  3356.039733  3356.71862  3367.570947  2.508297           1  \n",
       "31  1.9862  3358.064533  3356.62247  3366.435643  3.299309           1  \n",
       "32  2.2541  3360.299800  3356.95353  3365.803543  3.513844           1  \n",
       "33  0.5791  3362.508000  3357.73911  3365.386290  3.079289           1  \n",
       "34  0.5452  3364.194500  3358.75224  3365.018567  2.431807           0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new features\n",
    "dataset['H-L'] = dataset['high'] - dataset['low']\n",
    "dataset['O-C'] = dataset['close'] - dataset['open']\n",
    "dataset['3m MA'] = dataset['close'].shift(1).rolling(window = 3).mean() # 3 mins moving average\n",
    "dataset['10m MA'] = dataset['close'].shift(1).rolling(window = 10).mean()\n",
    "dataset['30m MA'] = dataset['close'].shift(1).rolling(window = 30).mean()\n",
    "dataset['Std_dev']= dataset['close'].rolling(5).std()\n",
    "\n",
    "# Define dummy variable: trend of stock price\n",
    "dataset['Price_Rise'] = np.where(dataset['close'].shift(-1) > dataset['close'], 1, 0)\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is: \n",
      " (318342, 1, 8)\n"
     ]
    }
   ],
   "source": [
    "# Extract X and y\n",
    "X = dataset.iloc[:, 4:-1]\n",
    "y = dataset.iloc[:, -1]\n",
    "\n",
    "# Create training and testing sets\n",
    "split = int(len(dataset)*0.8)\n",
    "X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n",
    "\n",
    "# Normalize the feature values\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# reshaping - Adding time interval as a dimension for input.\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1])) # time_steps = 1\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "print('The shape of X_train is: \\n', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "318342/318342 [==============================] - 10s - loss: 0.6134 - acc: 0.6706    \n",
      "Epoch 2/30\n",
      "318342/318342 [==============================] - 10s - loss: 0.6002 - acc: 0.6747    \n",
      "Epoch 3/30\n",
      "318342/318342 [==============================] - 10s - loss: 0.5987 - acc: 0.6747    \n",
      "Epoch 4/30\n",
      "318342/318342 [==============================] - 10s - loss: 0.5979 - acc: 0.6750    \n",
      "Epoch 5/30\n",
      "318342/318342 [==============================] - 10s - loss: 0.5973 - acc: 0.6751    \n",
      "Epoch 6/30\n",
      "318342/318342 [==============================] - 9s - loss: 0.5969 - acc: 0.6749     \n",
      "Epoch 7/30\n",
      "318342/318342 [==============================] - 11s - loss: 0.5966 - acc: 0.6749    \n",
      "Epoch 8/30\n",
      "318342/318342 [==============================] - 11s - loss: 0.5964 - acc: 0.6753    \n",
      "Epoch 9/30\n",
      "318342/318342 [==============================] - 10s - loss: 0.5961 - acc: 0.6754    \n",
      "Epoch 10/30\n",
      "318342/318342 [==============================] - 10s - loss: 0.5960 - acc: 0.6752    \n",
      "Epoch 11/30\n",
      "318342/318342 [==============================] - 10s - loss: 0.5958 - acc: 0.6758    \n",
      "Epoch 12/30\n",
      "318342/318342 [==============================] - 11s - loss: 0.5957 - acc: 0.6757    \n",
      "Epoch 13/30\n",
      "318342/318342 [==============================] - 11s - loss: 0.5955 - acc: 0.6760    \n",
      "Epoch 14/30\n",
      "318342/318342 [==============================] - 11s - loss: 0.5955 - acc: 0.6756    \n",
      "Epoch 15/30\n",
      "318342/318342 [==============================] - 10s - loss: 0.5954 - acc: 0.6762    \n",
      "Epoch 16/30\n",
      "318342/318342 [==============================] - 10s - loss: 0.5953 - acc: 0.6760    \n",
      "Epoch 17/30\n",
      "318342/318342 [==============================] - 12s - loss: 0.5952 - acc: 0.6760    \n",
      "Epoch 18/30\n",
      "318342/318342 [==============================] - 10s - loss: 0.5951 - acc: 0.6762    \n",
      "Epoch 19/30\n",
      "318342/318342 [==============================] - 11s - loss: 0.5951 - acc: 0.6762    \n",
      "Epoch 20/30\n",
      "318342/318342 [==============================] - 10s - loss: 0.5949 - acc: 0.6762    \n",
      "Epoch 21/30\n",
      "318342/318342 [==============================] - 10s - loss: 0.5949 - acc: 0.6760    \n",
      "Epoch 22/30\n",
      "318342/318342 [==============================] - 10s - loss: 0.5948 - acc: 0.6763    \n",
      "Epoch 23/30\n",
      "318342/318342 [==============================] - 11s - loss: 0.5948 - acc: 0.6758    \n",
      "Epoch 24/30\n",
      "318342/318342 [==============================] - 10s - loss: 0.5947 - acc: 0.6761    \n",
      "Epoch 25/30\n",
      "318342/318342 [==============================] - 9s - loss: 0.5947 - acc: 0.6761     \n",
      "Epoch 26/30\n",
      "318342/318342 [==============================] - 10s - loss: 0.5946 - acc: 0.6758    \n",
      "Epoch 27/30\n",
      "318342/318342 [==============================] - 10s - loss: 0.5946 - acc: 0.6761    \n",
      "Epoch 28/30\n",
      "318342/318342 [==============================] - 10s - loss: 0.5946 - acc: 0.6760    \n",
      "Epoch 29/30\n",
      "318342/318342 [==============================] - 10s - loss: 0.5945 - acc: 0.6760    \n",
      "Epoch 30/30\n",
      "318342/318342 [==============================] - 10s - loss: 0.5945 - acc: 0.6761    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a20385550>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the RNN(LSTM)\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "# Initialising the RNN\n",
    "# Creating an object of Sequential class to create the RNN.\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the LSTM layer\n",
    "# input_shape = (len_of_seq, nb_of_features)\n",
    "classifier.add(LSTM(units = 32, activation = 'relu', input_shape = (X_train.shape[1],X_train.shape[2]), return_sequences=False))\n",
    "\n",
    "# Adding the output layer\n",
    "# 1 nueron in the output layer for 1 dimensional output\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the RNN\n",
    "# Compiling all the layers together.\n",
    "# Loss helps in manipulation of weights in NN. \n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "# Number of epochs increased for better convergence.\n",
    "classifier.fit(X_train, y_train, batch_size = 200, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78784/79586 [============================>.] - ETA: 0s\n",
      "acc: 68.92%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "scores = classifier.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"\\n%s: %.2f%%\" % (classifier.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Conclusion\n",
    "\n",
    "1. Present the detailed steps of the exercise (1 points)\n",
    "> The general idea is:\n",
    ">- Load and clean data; \n",
    ">- Inside each of the 3 model, split dataset into training and testing sets;\n",
    ">- Apply deep learning algorithms while deal with overfitting carefully; \n",
    ">- Evaluate models' performance and choose the final model.\n",
    "2. Find your final best model (highest accuracy you can get) (2 points)\n",
    "> The best model is model 3, with 68.92% accuracy rate.<br>\n",
    ">- $$ y_{t+1} = f(HL, OC, 3m MA, 10m MA, 30m MA, volatility) $$\n",
    ">- **Reasons:**\n",
    ">- The problem in this case belongs to time series prediction, and it adds the complexity of a sequence dependence among the input variables. The LSTM network is a type of recurrent neural network, which is designed to deal with sequential data. With LSTM, large architectures can be successfully trained, while deep NN cannot find the pattern effectively.\n",
    ">- Feature engineering. Instead of the original variables, we created new features including **spreads, moving average and volatility**. This process can help the model extract useful data while filter the redundant information.\n",
    "3. Evaluate the performance of the model (1 points)\n",
    ">- According to the evaluation matrix on testing set, the model loss is 0.5739 and the accuracy rate is 0.6892.\n",
    ">- A great improvement compared with other models.\n",
    "4. Code (2 points)\n",
    ">- Please refer the Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
